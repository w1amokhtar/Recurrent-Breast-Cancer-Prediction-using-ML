{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUCoL6xH5rEp"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTy2MnTGJoO3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder #to encode categorical data\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report #for evaluation\n",
        "from sklearn.preprocessing import StandardScaler #feature scaling\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCGHvcWN5T1H"
      },
      "source": [
        "# **Upload Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPPtFajaJuul"
      },
      "outputs": [],
      "source": [
        "#Upload the csv file before running this cell\n",
        "dataset= pd.read_csv(\"/content/dataset.csv\")\n",
        "dataset.sample(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnVmwhPCdqkd"
      },
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "**there are some \"?\" values is data.**\n",
        "\n",
        "**First, replace them with NaN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkT66idZdqH1"
      },
      "outputs": [],
      "source": [
        "dataset.replace('?', np.nan, inplace = True)\n",
        "#check how many values are NaN\n",
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZznJgO8bMvw"
      },
      "source": [
        "**shape before removing missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2OyO3qserNH"
      },
      "outputs": [],
      "source": [
        "print(\"Cancer data set dimensions : {}\".format(dataset.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvu9KGnbZlw"
      },
      "source": [
        "**since there aren't many missing values, we can remove them from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zItJQ7smfk76"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIdB3gblbf6a"
      },
      "source": [
        "**shape after removing missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xzPPalYfsmI"
      },
      "outputs": [],
      "source": [
        "print(\"Cancer data set dimensions after removing missing values : {}\".format(dataset.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YisRm7OoU0QS"
      },
      "outputs": [],
      "source": [
        "#to change the default number of columns to be displayed\n",
        "pd.set_option(\"display.max_columns\", 35)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLXDFqGX9PgD"
      },
      "source": [
        "**Drop ID Column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZBye_Sz9PgD"
      },
      "outputs": [],
      "source": [
        "dataset.drop(columns=['id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "ivnY-gI2AK1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNWQML29PgE"
      },
      "source": [
        "**change data types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiPTp9aE9PgE"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.astype({\"Recurrence\":'category', \"Lymph node status\":'float', \"Time\":'float'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "NWU21Yu_ATAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoOeDvz89PgE"
      },
      "source": [
        "**encoding categorical data: converting categorical data into integer format so it can be provided to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh1eXq9S9PgE"
      },
      "outputs": [],
      "source": [
        "labelencoder = LabelEncoder()\n",
        "dataset['Recurrence'] = labelencoder.fit_transform(dataset['Recurrence'])\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNO9mnR5isR"
      },
      "source": [
        "# **Data Splitting (x,y)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPvc-6gvb1Qz"
      },
      "source": [
        "**we want to predict Y**\n",
        "\n",
        "**iloc: select a specific row or column from the data set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThmjTEsdKs_a"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:,dataset.columns != 'Recurrence']\n",
        "Y = dataset['Recurrence']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EezYqB0scBJv"
      },
      "source": [
        "**X contains all feature values, Y contains the class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6-M6I8bLMX6"
      },
      "outputs": [],
      "source": [
        "X,Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My9__KSc9PgF"
      },
      "source": [
        "**the values of features vary in range, we need to perform feature scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOSZg4iN9PgF"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X)"
      ],
      "metadata": {
        "id": "6oQKbvIrjXtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCfRBcdKcTfX"
      },
      "source": [
        "**to get the number of data point in each class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZISJOBYLY20"
      },
      "outputs": [],
      "source": [
        "dataset['Recurrence'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnqpz8A59PgF"
      },
      "source": [
        "**performing oversampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w16qpNEe9PgF"
      },
      "outputs": [],
      "source": [
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X, Y = oversample.fit_resample(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCy-Fr3l7EtN"
      },
      "source": [
        "# **Data Splitting (training, testing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjRMDnzl99Av"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0)\n",
        "Y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EURI97v0-EL7"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK50phpzPA7s"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "\n",
        "Here, we used gaussian naive bayes because we have variables with continous values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDxPFBlJ-JjM"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# instantiate the model\n",
        "gnb_classifier = GaussianNB()\n",
        "# fit the model\n",
        "gnb_classifier.fit(X_train, Y_train)\n",
        "#predict result\n",
        "gnb_y_pred = gnb_classifier.predict(X_test)\n",
        "print('Training set: {:.2f}%'.format(gnb_classifier.score(X_train, Y_train)*100))\n",
        "print('Testing set: {:.2f}%'.format(gnb_classifier.score(X_test, Y_test)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hoxqBT3PG1y"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTh51e42Oh5n"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svc_classifier = SVC(kernel='linear')\n",
        "svc_classifier.fit(X_train, Y_train)\n",
        "svc_y_predict = svc_classifier.predict(X_test)\n",
        "print('Training set: {:.2f}%'.format(svc_classifier.score(X_train, Y_train)*100))\n",
        "print('Testing set: {:.2f}%'.format(svc_classifier.score(X_test, Y_test)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6k_HS-6MTSH"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YqoGn_EMYVL"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "DT_classifier = DT(criterion = \"entropy\", random_state = 100, \tmax_depth = 3, min_samples_leaf = 5)\n",
        "DT_classifier.fit(X_train, Y_train)\n",
        "DT_y_predict= DT_classifier.predict(X_test)\n",
        "print('Training set: {:.2f}%'.format(DT_classifier.score(X_train, Y_train)*100))\n",
        "print('Testing set: {:.2f}%'.format(DT_classifier.score(X_test, Y_test)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCe-TyJD9PgS"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsw-7DGI9PgS"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier()\n",
        "forest.fit(X_train, Y_train)\n",
        "rf_y_predict= forest.predict(X_test)\n",
        "print('Training set: {:.2f}%'.format(forest.score(X_train, Y_train)*100))\n",
        "print('Testing set: {:.2f}%'.format(forest.score(X_test, Y_test)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aYjzCazOAKF"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2yxJ-FnLUTd"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiYB8QU7OIZi"
      },
      "outputs": [],
      "source": [
        "# create confusion matrix\n",
        "gnb_cm=confusion_matrix(Y_test,gnb_y_pred)\n",
        "# display the matrix\n",
        "sns.heatmap(gnb_cm,annot=True)\n",
        "# set title\n",
        "plt.title(\"confusion matrix for Naive Bayes\")\n",
        "# print classification report\n",
        "print(classification_report(Y_test, gnb_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scRxuwGVqP_c"
      },
      "outputs": [],
      "source": [
        "svc_cm=confusion_matrix(Y_test,svc_y_predict)\n",
        "sns.heatmap(svc_cm,annot=True)\n",
        "plt.title(\"confusion matrix for SVM\")\n",
        "print(classification_report(Y_test, svc_y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W91y_23OV0ZF"
      },
      "outputs": [],
      "source": [
        "DT_cm=confusion_matrix(Y_test,DT_y_predict)\n",
        "sns.heatmap(DT_cm,annot=True)\n",
        "plt.title(\"confusion matrix for Decision tree\")\n",
        "print(classification_report(Y_test,DT_y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj2u3vdJ9PgT"
      },
      "outputs": [],
      "source": [
        "rf = confusion_matrix(Y_test, rf_y_predict)\n",
        "sns.heatmap(rf, annot=True)\n",
        "plt.title(\"confusion matrix for Random Forest\")\n",
        "print(classification_report(Y_test,rf_y_predict))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}